type: "WrapperDataset"
config:
  root: "${paths.datasets}/semantic-kitti/dataset=semantic-kitti,format=orig"
  cache_root: "${paths.datasets}/semantic-kitti/dataset=semantic-kitti,format=npy"
  split: "train"
  sequences: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10]
  pre_transform:
    - ToDict: {wrapper: "torch_geometric.data.Data"}
    - RandomSample: {num: 16384, attrs: ["pos", "remission", "raw_semantic_index", "semantic_index", "instance_index"], static_seed: 1234}
    - ToDict: {wrapper: "dict"}
  _wrapper:
    type: "SemanticKittiDataset"
    transform_keys: ["pre_transform"]
loader:
  shuffle: True
  batch_size: 32
  num_workers: 4
settings:
transforms:
  # transform:
  - ToDict: {wrapper: "torch_geometric.data.Data"}
  - RandomSample: {num: "${hp.num_points}", attrs: ["pos", "remission", "raw_semantic_index", "semantic_index", "instance_index"]}
  - ToDict: {wrapper: "dict"}
meta:
  name: "SemanticKITTI"
  identifier: null
  num_samples: 19130
  steps_per_epoch:
